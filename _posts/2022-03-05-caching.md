---
layout: post
title:  "[系统设计] 缓存 Caching"
date: 2022-03-05 21:28:05-08:00
categories: systemdesign
---
缓存`caching`用来
- 加速系统，即减少系统的latency
- 减少server和database压力

几个latency数据:
- 内存里读1MB, 0.25ms
- SSD里读1MB, 1ms
- 网络传输1MB, 10ms
- HDD里读1MB, 20ms
- 洲际往返传输, 150ms

Caching可以在client这边做，也可以在server这边做，也可以在硬件层面做，比如CPU cache。现代处理器里的L1,L2,L3 cache容量依次变大，速度依次变慢。CPU的每个core有自己的L1 cache和L2 cache。一个die(晶粒，从晶圆上切割下来的一个个小方块)上的所有cores共享L3 cache。

从数据库读数据比较费时，因此可以缓存到server里节省时间。写缓存有两种策略: `write-through`(写穿)和`write-back`(写回，又叫write-behind)。write-through同时更新cache和数据库，速度慢。write-back只更新cache，在cache填满要移除数据时再更新数据库，速度快。或者定时更新数据库，比如每5分钟写一次。但在更新数据库时如果断电，数据会丢失。

缓存里的数据会过时(stale)，需要明确我们是否关心数据的staleness。在一个大型系统中，如果每个server都维护自己的缓存，且采用write-back，那么client在不同server读到的内容就不一致。如果关心数据accuracy，比如帖子的评论，可以用single cache，比如Redis。所有server来读写Redis，这样所有server都能拿到准确数据。如果不关心数据accuracy，staleness可以接受，比如Youtube视频的view count，此时每个server保留自己的缓存就可以。

缓存满了以后，需要驱逐(evict)一些数据。常见策略有LRU(Least Recently Used，删掉最近没用过的数据)，LFU(Least Frequently Used，删掉使用频率最低的数据，数据最近使用了但使用频率很低也可能被删掉)，FIFO(First In First Out)。

缓存的另一个例子是CDN(Content Delivery Network，内容分发网络)。CDN服务商有遍布全球的server，CDN server的地理位置离用户更近，因而latency更小，著名的CDN服务商有Cloudflare和Google Cloud CDN。

几个无脑用缓存的情况:
- 内容是静态不变的
- 只有一个client在读写数据
- 不关心数据的accuracy/staleness
- 系统很容易删掉/驱逐过时的数据
