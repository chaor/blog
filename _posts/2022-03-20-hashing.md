---
layout: post
title:  "[系统设计] 哈希 Hashing"
date: 2022-03-20 17:45:10-07:00
categories: systemdesign
---
哈希(Hash)是把变长数据映射成定长数据的过程。映射成的定长数据越长，越不容易产生哈希碰撞。安全的哈希函数不应产生哈希碰撞。

Hash table(哈希表)是一个key-value data store。增加/删除/查找一个key value pair都只需要average O(1)的时间，最快情况O(n)的时间。哈希表用dynamic array of linked list实现，我们用哈希函数`hash function`把一个key转化成dynamic array的index，key的reference和value会存在这个index对应的linked list里，注意没必要再复制一遍key。哈希碰撞`collision`是指两个key算出了同一个index，选择哈希函数时应尽量避免哈希碰撞。平常编程用的哈希结构无需考虑O(n) worst time，因为哈希函数已经非常优化了，可以认为哈希函数复杂度为O(1)且无碰撞，减少`hashing collision`又叫增加`uniformity`。dynamic array在空间不够用时，会进行resize，比如当占用率达到三分之二，double the size，更新哈希函数，用新的array size来取模。当占用率很小时，也会缩小array size。

当Load Balancer选server时，为了保证同一个client的request或者同一个request总能到达同一个server以便利用server的in-memory cache，可以用哈希函数算出哈希值，对server总数取模。

如果我们增加了或减少了一台server呢? 对server总数取模得到的就不是原来的server了，没法利用原server的in-memory cache了。1997年提出的`Consistent hashing`一致性哈希可以解决这个问题。把server和client都放到一个圆环上，从一个client开始，顺时针或逆时针转，选择第一个碰到的server来服务。这样增加或减少一个server时，大多数client对应的server还是不变的，即保证了client被分到server的一致性。为了让负载更加均衡，可以对这些server使用多个哈希函数，让同一个server在圆环上出现多次。如果server A很强大，server B,C,D一般，可以让A在圆环上出现更多次，以便得到更多的client requests。可以用一个数组来实现一致性哈希，把server用不同的哈希函数映射到数组上。client也映射到数组上，往右走，选碰到的第一个server。

发表于1997年的`rendezvous hashing` or `highest random weight (HRW) hashing`高随机权重哈希比一致性哈希更简单更通用。思路是对每个client request，给所有server打分，选得分最高的server，即highest ranking server。只要增加或删除的不是某个client对应的得分最高server，这个client对应的server就不受影响。算分数时需要多次试验，比如`score = (clientHash * 13 + serverHash * 17) % 67`。

当大型系统中的server用in-memory cache时，应考虑使用`consistent hashing`或`rendezvous hashing`，效果会比naive hashing好得多。

SHA是`Secure Hash Algorighms`的简称，是业界用到的加密哈希函数的集合，如今发布于2015年的SHA-3比较流行。SHA-2发布于2001年，SHA-1发布于1995年。
Python的`hashlib.algorithms_guaranteed`列出了这个模块全平台支持的哈希算法，`hashlib.algorithms_available`列出了当前解释器支持的哈希算法。

{% highlight python linenos %}
>>> import hashlib

>>> hashlib.algorithms_guaranteed
{'sha256', 'sha3_256', 'sha1', 'shake_128', 'blake2s', 'sha224', 'sha512', 'sha3_512', 'shake_256', 'sha3_224', 'md5', 'sha3_384', 'sha384', 'blake2b'}

>>> hashlib.algorithms_available
{'sha256', 'md5-sha1', 'sha3_256', 'blake2s', 'sha512_256', 'mdc2', 'sha512', 'shake_256', 'md5', 'blake2b', 'sha512_224', 'sha3_512', 'sm3', 'sha384', 'shake_128', 'ripemd160', 'sha3_224', 'whirlpool', 'sha1', 'sha224', 'md4', 'sha3_384'}
{% endhighlight %}

哈希后得到的定长数据叫`message digest`或`digest`。比如Python的`hashlib.sha3_512().digest_size`是64个bytes，所以调用`.hexdigest()`方法时会得到一个长度为128的字符串。512个比特的定长数据非常大，2 ** 512 = 1.34 * (10 ** 154)，基本不可能产生哈希碰撞。诞生于1992年的MD5已是不安全的哈希算法了，它的digest有128比特。谷歌在2017年宣布了SHA1的第一个碰撞(https://shattered.io/)，SHA1的digest有160比特，SHA1也不再安全。Git也在用SHA1来标记文件，目录和revision(revision is a tracked state of project, 每个revision有自己的SHA1 hash)。It’s more urgent than ever for security practitioners to migrate to safer cryptographic hashes such as SHA-256 and SHA-3.
