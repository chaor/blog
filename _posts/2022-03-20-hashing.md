---
layout: post
title:  "[系统设计] 哈希 Hashing"
date: 2022-03-20 17:45:10-07:00
categories: systemdesign
---
Hash table(哈希表)是一个key-value data store。增加/删除/查找一个key value pair都只需要average O(1)的时间，最快情况O(n)的时间。哈希表用dynamic array of linked list实现，我们用哈希函数`hash function`把一个key转化成dynamic array的index，key的reference和value会存在这个index对应的linked list里，注意没必要再复制一遍key。哈希碰撞`collision`是指两个key算出了同一个index，选择哈希函数时应尽量避免哈希碰撞。平常编程用的哈希结构无需考虑O(n) worst time，因为哈希函数已经非常优化了，可以认为哈希函数复杂度为O(1)且无碰撞，减少`hashing collision`又叫增加`uniformity`。dynamic array在空间不够用时，会进行resize，比如当占用率达到三分之二，double the size，更新哈希函数，用新的array size来取模。当占用率很小时，也会缩小array size。

当Load Balancer选server时，为了保证同一个client的request或者同一个request总能到达同一个server以便利用server的in-memory cache，可以用哈希函数算出哈希值，对server总数取模。

如果我们增加了或减少了一台server呢? 对server总数取模得到的就不是原来的server了，没法利用server的in-memory cache了。这里用到`consistent hashing`一致性哈希。把server和client都放到一个圆环上，从一个client开始，顺时针或逆时针转，选择第一个碰到的server来服务。这样增加或减少一个server时，大多数client对应的server还是不变的，即保证了client被分到server的一致性。为了让负载更加均衡，可以对这些server使用多个哈希函数，让同一个server在圆环上出现多次。如果server A很强大，server B,C,D一般，可以让A在圆环上出现更多次，以便得到更多的client requests。

发表于1997年的`rendezvous hashing` or `highest random weight (HRW) hashing`高随机权重哈希比一致性哈希更简单更通用。思路是对每个client request，给所有server打分，选得分最高的server，即highest ranking server。只要增加或删除的不是某个client对应的得分最高server，这个client对应的server就不受影响。算分数时需要多次试验，比如`score = (clientHash * 13 + serverHash * 17) % 67`。

当大型系统中的server用in-memory cache时，应考虑使用`consistent hashing`或`rendezvous hashing`，效果会比naive hashing好得多。

SHA是`Secure Hash Algorighms`的简称，是业界用到的加密哈希函数的集合，如今发布于2015年的SHA-3比较流行。SHA-2发布于2001年，SHA-1发布于1995年。

Python的`hashlib.algorithms_guaranteed`列出了这个模块全平台支持的哈希算法，`hashlib.algorithms_available`列出了当前解释器支持的哈希算法。数据用哈希算法计算得出的结果叫`message digest`或`digest`。`.digest_size`用来看消息摘要有几个byte。比如 `hashlib.sha3_512().digest_size`是64个bytes，所以调用`.hexdigest()`方法时会得到一个长度为128的字符串。
